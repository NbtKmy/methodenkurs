<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body onload="getLib()">
		<div class="reveal">
			<div class="slides">
				<section>
					<h2>Using statistical data and Text mining in Social Sciences</h2>
				</section>
				<section>
					<section data-markdown>
						## Goal

						* Learning research possibilities with data & text mining
						* ...and some methods 
						* Getting critical insight about managing data
					</section>
					<section data-markdown>
						## Key terms in Japanese:

						* 地理情報システム = GIS (geographic information system(s))
						* 計量テキスト分析 = text mining or statistical analysis of text
						* テキストマイニング = text mining
						* 共起表現 = co-occurrence or collocation
						* 単語の埋め込み = word embedding
					</section>
				</section>
				<section>
					<section>
						<h2>Example 1</h2>
						<h2>GIS (geographic information system(s))</h2>						
					</section>
					<section>
						<h1>What you get?</h1>
					</section>
					<section>
						<h3>Density of population on the map</h3>
						<img src="./img/shiga_populationmap.png" style="height: 500px; margin: 0 auto 4rem auto; background: transparent;" class="demo1">
					</section>
					<section data-markdown>
						## Technical requirements

						* [QGIS (Software)](https://www.qgis.org/en/site/)
						* Statistical and geographical data ([e-Stat](https://www.e-stat.go.jp/gis))
					</section>
					<section data-markdown>
						## Advantages of the visualization?

						* Getting densities intuitively
						* Rising more questions from the visual expression
						* ... and they might bring you to new findings
					</section>
				</section>
				<section>
					<section>
						<h2>Example 2</h2>
						<h2>Text mining (co-occurrence or collocation)</h2>
					</section>
					<section>
						<h3>Co-occurrence = an above-chance frequency of occurrence of two terms from a text corpus alongside each other in a certain order</h3>
					</section>
					<section>
						<h2>What you get?</h2>
					</section>
					<section>
						<h3>Visualizing the co-occurrence of the vocabulary in all press conferences of the former Prime minister Kan Naoto</h3>
					</section>
					<section>
						<img src="./img/kan_pk_top100_Neologd.png" style="height: 700px; margin: 0 auto 4rem auto; background: transparent;" class="demo2_1">
					</section>
					<section>
						<img src="./img/kan_pk_top100_withoutWatasi.png" style="height: 700px; margin: 0 auto 4rem auto; background: transparent;" class="demo2_2">
					</section>
					<section data-markdown>
						## Technical requirements

						* Text corpus from [WARP-Seite](https://warp.ndl.go.jp/info:ndljp/pid/2629568/www.kantei.go.jp/jp/kan/statement/index.html)! 
						* Python libraries wie pandas, numpy, matplotlib usw.
						* Software for the morphological analysis ([MeCab](https://www.mlab.im.dendai.ac.jp/~yamada/ir/MorphologicalAnalyzer/MeCab.html)) and dictionary (ex. [NEologd](https://github.com/neologd/mecab-ipadic-neologd))
					</section>
					<section data-markdown>
						## Advantages of the visualization?

						* Getting co-occurrences and word frequency intuitively
						* Visualization can support your interpretation
						* ... and they might bring you to new findings
					</section>
					<section data-markdown>
						## Caution - Rules for web crawling

						* Many websites have Robots Exclusion Standard (RES) 
						* A "robots.txt"-protocol under http[s]://[domain name]/robots.txt
						* The protocol expresses the rules for/against the web crawling.
						* Example: https://ja.wikipedia.org/robots.txt
					</section>
				</section>
				<section>
					<section>
						<h2>Example 3</h2>
						<h2>Word embedding</h2>						
					</section>
					<section>
						<h3>Word embedding = representation of words in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning</h3>
					</section>
					<section>
						<img src="https://www.tensorflow.org/images/linear-relationships.png" style="height: 350px; margin: 0 auto 4rem auto; background: transparent;" class="demo3_0">
						<p>image from: https://www.tensorflow.org/images/linear-relationships.png</p>
					</section>
					<section>
						<h2>What you get?</h2>
					</section>
					<section>
						<h3>Collecting tweets with the word "オリンピック (Olympic)" and analysis with word embedding</h3>
					</section>
					<section>
						<h3>Similar words to "オリンピック & 日本"</h3>
						<img src="./img/w2v_olympicUndJapan.png" style="height: 500px; margin: 0 auto 4rem auto; background: transparent;" class="demo3_1">
					</section>
					<section>
						<h3>Similar words to "日本"</h3>
						<img src="./img/w2v_nihon.png" style="height: 500px; margin: 0 auto 4rem auto; background: transparent;" class="demo3_2">
					</section>
					<section>
						<h3>Similar words to "オリンピック" in 2D-Mapping</h3>
					</section>
					<section>
						<img src="./img/w2v_plot.png" style="height: 700px; margin: 0 auto 4rem auto; background: transparent;" class="demo3_３">
					</section>
					<section data-markdown>
						## Technical requirements

						* Text corpus from [Twitter (API-Key)](https://developer.twitter.com/en/docs)
						* Python libraries like [tweepy](https://www.tweepy.org/), [gensim](https://radimrehurek.com/gensim/) usw.
						* Software for the morphological Analysis ([MeCab](https://www.mlab.im.dendai.ac.jp/~yamada/ir/MorphologicalAnalyzer/MeCab.html)) and dictionary (ex. [NEologd](https://github.com/neologd/mecab-ipadic-neologd))
					</section>
					<section data-markdown>
						## Advantages of the word embedding?

						* Getting words (or meanings) as vector 
						* Word vector space model can be used syntactic analysis and sentiment analysis
						* ... and they might bring you to new findings
					</section>
					<section data-markdown>
						## Caution - legal & ethical aspect for the data analysis & the publishing the results

						* According to the Japanese Copyright Act, Art. 47-7, the copying the data for the purpose of the data analysis is permitted
						* If you will/should publish the data, the personal information must be at least anonymized for the privacy protection
						* In this example I've removed all Twitter-IDs
					</section>
				</section>
				<section>
					<section>
						<h1>Playing with data</h1>
					</section>
					<section data-markdown>
						# Step 1
						## Choose a text corpus from [here](https://github.com/NbtKmy/methodenkurs/tree/main/training)
						* Text from press conferences of the former prime minister Kan Naoto (Japanese)
						* Text corpus from Twitter (Japanese, anonymized)
						* Text corpus from [Reuters-21578](https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection) (English)
					</section>
					<section data-markdown>
						# Step 2
						## Then put it in [Voyant Tool](https://voyant-tools.org/)
						* What happens at first?
						* Create your own stop words list
						* And see what happens (for example word cloud)
						* Compare your result with your colleagues
					</section>
					<section data-markdown>
						# Step 3
						## Discussion
						* How many influence you have on the result?
						* Is the result then objective?
						* What is important, if you want to use the data for your research?
					</section>
				</section>
				<section>
					<section>
						<h1>Literature</h1>
					</section>
					<section>
						<h3>Researches with text mining on Japanese topics</h3>
						<div id="output"></div>
					</section>
					<section>
						<h3>Further readings 1</h3>
						<div id="output2"></div>
					</section>
					<section>
						<h3>Further readings 2</h3>
						<div id="output3"></div>
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="./getLib.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
